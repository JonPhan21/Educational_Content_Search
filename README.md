# Educational Content Search

A powerful search engine for educational content that helps students and educators find relevant learning materials quickly and efficiently.

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Technologies Used](#technologies-used)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project was developed during a hackathon to solve the problem of finding quality educational content across multiple platforms. The search engine uses advanced algorithms to index and retrieve educational materials based on relevance, quality, and user preferences.

## âœ¨ Features

- **Smart Search**: AI-powered search with natural language processing
- **Content Filtering**: Filter by subject, difficulty level, content type
- **Quality Scoring**: Automatic content quality assessment
- **Multi-platform Support**: Search across various educational platforms
- **User Preferences**: Personalized search results
- **DOCX Scraping**: Automated scraping of educational DOCX files

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Quick Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/JonPhan21/Educational_Content_Search.git
   cd Educational_Content_Search
   ```

2. **Run the setup script**
   ```bash
   ./scripts/setup_environment.sh
   ```

### Manual Setup

1. **Create virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Environment setup**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys and configuration
   ```

## ğŸ’¡ Usage

### Running the DOCX Scraper

## ğŸ“ Project Structure

```
Educational_Content_Search/
â”œâ”€â”€ .env.example                    # Environment variables template
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ setup.py                        # Package setup configuration
â”œâ”€â”€ src/                           # Source code
â”‚   â””â”€â”€ educational_search/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py                # Main application entry point
â”‚       â”œâ”€â”€ scrapers/              # Web scraping modules
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ docx_scraper.py    # DOCX file scraper
â”‚       â””â”€â”€ utils/                 # Utility functions
â”‚           â””â”€â”€ __init__.py
â”œâ”€â”€ data/                          # Data storage
â”‚   â”œâ”€â”€ raw/                       # Raw scraped data
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â””â”€â”€ downloaded_docx_files/ # Downloaded DOCX files
â”‚   â””â”€â”€ processed/                 # Processed data
â”‚       â””â”€â”€ .gitkeep
â”œâ”€â”€ tests/                         # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_scrapers.py          # Scraper tests
â”œâ”€â”€ docs/                          # Documentation
â”‚   â””â”€â”€ api.md                     # API documentation
â””â”€â”€ scripts/                       # Utility scripts
    â””â”€â”€ setup_environment.sh       # Environment setup script
```

## ğŸ›  Technologies Used

- **Python 3.8+**: Core programming language
- **Requests**: HTTP library for web scraping
- **BeautifulSoup4**: HTML/XML parsing for content extraction
- **python-docx**: DOCX file processing
- **NLTK**: Natural Language Processing toolkit
- **Pandas & NumPy**: Data manipulation and analysis
- **AWS Bedrock**: AI/ML services integration

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
python -m pytest tests/

# Run specific test file
python -m pytest tests/test_scrapers.py

# Run with coverage
python -m pytest tests/ --cov=src/educational_search
```

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Setup

```bash
# Install development dependencies
pip install -r requirements.txt

# Run tests
python -m pytest

# Run linting
flake8 src/
black src/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Hackathon organizers and mentors
- Asian American Education organization for content source
- Open source libraries and tools used

## ğŸ“ Contact

- **Project Team**: Educational Search Team
- **Repository**: https://github.com/JonPhan21/Educational_Content_Search

---

*Built with â¤ï¸ during Hackathon 2025*

### Using the DocxScraper Class

```python
from educational_search.scrapers.docx_scraper import DocxScraper

# Initialize scraper
scraper = DocxScraper()

# Scrape files (downloads to data/raw/downloaded_docx_files/)
count = scraper.scrape_docx_files(max_files=50)
print(f"Downloaded {count} files")
```